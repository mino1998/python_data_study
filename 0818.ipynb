{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92dee736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "# 한글 출력을 위한 설정\n",
    "from matplotlib import font_manager, rc\n",
    "import platform\n",
    "if platform.system()=='Darwin':\n",
    "    rc('font', family='AppleGothic')\n",
    "elif platform.system()=='Windows':\n",
    "    font_name=font_manager.FontProperties(fname='c:/Windows/Fonts/malgun.ttf').get_name()\n",
    "    rc('font', family=font_name)\n",
    "# 음수 사용(마이너스 기호 깨짐 방지)\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb09448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0  3504.0          12.0   \n",
       "1  15.0          8         350.0       165.0  3693.0          11.5   \n",
       "2  18.0          8         318.0       150.0  3436.0          11.0   \n",
       "3  16.0          8         304.0       150.0  3433.0          12.0   \n",
       "4  17.0          8         302.0       140.0  3449.0          10.5   \n",
       "\n",
       "   model year  origin                       name  \n",
       "0          70       1  chevrolet chevelle malibu  \n",
       "1          70       1          buick skylark 320  \n",
       "2          70       1         plymouth satellite  \n",
       "3          70       1              amc rebel sst  \n",
       "4          70       1                ford torino  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# auto-mpg 데이터 읽어오기\n",
    "auto_mpg=pd.read_csv('./data/auto-mpg.csv', header=None)\n",
    "# 컬럼 이름 설정하기\n",
    "auto_mpg.columns=['mpg', 'cylinders', 'displacement', 'horsepower', 'weight',\n",
    "                 'acceleration', 'model year', 'origin', 'name']\n",
    "auto_mpg['horsepower'].replace('?',np.nan,inplace=True)\n",
    "auto_mpg.dropna(subset=['horsepower'],axis=0, inplace=True)\n",
    "auto_mpg['horsepower']=auto_mpg['horsepower'].astype('float')\n",
    "auto_mpg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91608fa9",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1429c7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horsepower</th>\n",
       "      <th>hp_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130.0</td>\n",
       "      <td>보통출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165.0</td>\n",
       "      <td>보통출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150.0</td>\n",
       "      <td>보통출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150.0</td>\n",
       "      <td>보통출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140.0</td>\n",
       "      <td>보통출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>198.0</td>\n",
       "      <td>고출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>220.0</td>\n",
       "      <td>고출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>215.0</td>\n",
       "      <td>고출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>225.0</td>\n",
       "      <td>고출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>190.0</td>\n",
       "      <td>고출력</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   horsepower hp_bin\n",
       "0       130.0   보통출력\n",
       "1       165.0   보통출력\n",
       "2       150.0   보통출력\n",
       "3       150.0   보통출력\n",
       "4       140.0   보통출력\n",
       "5       198.0    고출력\n",
       "6       220.0    고출력\n",
       "7       215.0    고출력\n",
       "8       225.0    고출력\n",
       "9       190.0    고출력"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One Hot Encoding\n",
    "# Horsepower 특성을 범주형으로 추가 - 3개의 영역으로 구분\n",
    "# 3개의 구간으로 구분해서 개수와 경계값을 리턴받아서 저장\n",
    "count,bin_dividers=np.histogram(auto_mpg['horsepower'],bins=3)\n",
    "# 범주형 형태로 생성\n",
    "auto_mpg['hp_bin']=pd.cut(x=auto_mpg['horsepower'],\n",
    "                         bins=bin_dividers,\n",
    "                         labels=['저출력', '보통출력', '고출력'],\n",
    "                         include_lowest=True)\n",
    "auto_mpg[['horsepower','hp_bin']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a637a625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>저출력</th>\n",
       "      <th>보통출력</th>\n",
       "      <th>고출력</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   저출력  보통출력  고출력\n",
       "0    0     1    0\n",
       "1    0     1    0\n",
       "2    0     1    0\n",
       "3    0     1    0\n",
       "4    0     1    0\n",
       "5    0     0    1\n",
       "6    0     0    1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원 핫 인코딩 수행 - 값이 3종류이므로, \n",
    "# 3개의 특성이 만들어지고 값은 하나만 1이다.\n",
    "horsepower_dummies=pd.get_dummies(auto_mpg['hp_bin'])\n",
    "horsepower_dummies.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9533c3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['고출력', '보통출력', '저출력'], dtype='<U4')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "one_hot=LabelBinarizer()\n",
    "one_hot.fit_transform(auto_mpg['hp_bin'])\n",
    "#이름확인\n",
    "one_hot.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e4234d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 1 0]\n",
      " [1 0 0 1 0 0 0]\n",
      " [0 0 0 1 1 0 0]\n",
      " [0 0 1 0 0 1 0]\n",
      " [0 0 0 0 0 1 1]]\n",
      "['c#' 'c++' 'go' 'java' 'kotlin' 'python' 'r']\n"
     ]
    }
   ],
   "source": [
    "# 2개 이상의 특성을 가지고 원 핫 인코딩이 가능합니다.\n",
    "# 2ㅐ 이상의 1이 등장할 수 있습니다.\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "multi_feature=[('java','c++'),('c++', 'python'), ('java', 'c#'),\n",
    "            ('java', 'kotlin'), ('python', 'go'), ('python', 'r')]\n",
    "one_hot_multiclass=MultiLabelBinarizer()\n",
    "print(one_hot_multiclass.fit_transform(multi_feature))\n",
    "print(one_hot_multiclass.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4619e33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Score  encoder\n",
      "0    저조        1\n",
      "1    보통        2\n",
      "2    보통        2\n",
      "3    저조        1\n",
      "4    우수        3\n",
      "5  매우우수        4\n"
     ]
    }
   ],
   "source": [
    "# 순서가 의미를 갖는 경우 - replace 함수 이용\n",
    "df=pd.DataFrame({\"Score\":['저조','보통','보통','저조','우수','매우우수']})\n",
    "scale_mapper={'저조':1,'보통':2,'우수':3,'매우우수':4}\n",
    "df['encoder']=df['Score'].replace(scale_mapper)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30185fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [2. 2.]\n",
      " [0. 1.]]\n",
      "[array(['High', 'Low', 'Normal'], dtype='<U11'), array(['10', '15', '20'], dtype='<U11')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "features=np.array([['Low',10],['Normal',20],['High',15]])\n",
    "ordinal_encoder=OrdinalEncoder()\n",
    "print(ordinal_encoder.fit_transform(features))\n",
    "print(ordinal_encoder.categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7878dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "[[ 0.    0.87  0.31]\n",
      " [ 1.   -0.67 -0.22]]\n",
      "[[ 0.    0.87  0.31]\n",
      " [ 1.   -0.67 -0.22]\n",
      " [ 0.    2.1   1.45]\n",
      " [ 1.    1.18  1.33]\n",
      " [ 0.    1.22  1.27]\n",
      " [ 1.   -0.21 -1.19]]\n"
     ]
    }
   ],
   "source": [
    "# 분류 모델을 이용한 결측값 대체\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# 훈련 데이터 생성\n",
    "X=np.array([[0,2.10,1.45],[1,1.18,1.33],[0,1.22,1.27],[1,-0.21,-1.19]])\n",
    "X_with_nan=np.array([[np.nan,0.87,0.31],[np.nan,-0.67,-0.22]])\n",
    "# KNN 학습기 생성\n",
    "clf=KNeighborsClassifier(3,weights='distance')\n",
    "# 첫 번째 데이터가 레이블이고 나머지 데이터를 feature로 설정해서 훈련하기\n",
    "# data, target 순으로 적어두었구나?\n",
    "trained_model=clf.fit(X[:,1:],X[:,0])\n",
    "# 예측\n",
    "imputed_values=trained_model.predict(X_with_nan[:,1:])\n",
    "print(imputed_values)\n",
    "# 예측한 데이터와 원본 데이터를 합치기\n",
    "# 옆으로 합치면 hstack\n",
    "X_with_imputed=np.hstack((imputed_values.reshape(-1,1),X_with_nan[:,1:]))\n",
    "print(X_with_imputed)\n",
    "# 결측치를 대체한 데이터와 훈련에 사용한 데이터를 합쳐보자.\n",
    "# 위 아애로 합치면 vstack을 사용합니다.\n",
    "result=np.vstack((X_with_imputed,X))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b920b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  nan  0.87  0.31]\n",
      " [  nan -0.67 -0.22]\n",
      " [ 0.    2.1   1.45]\n",
      " [ 1.    1.18  1.33]\n",
      " [ 0.    1.22  1.27]\n",
      " [ 1.   -0.21 -1.19]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  0.31],\n",
       "       [ 0.  , -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가장 많이 나오는 데이터로 대체\n",
    "from sklearn.impute import SimpleImputer\n",
    "X_complete=np.vstack((X_with_nan,X))\n",
    "print(X_complete)\n",
    "imputer=SimpleImputer(strategy='most_frequent')\n",
    "imputer.fit_transform(X_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5ddbef",
   "metadata": {},
   "source": [
    "### 정규표현식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35e8bab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 1), match='1'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# 매칭 여부를 확인하자\n",
    "match=re.match('[0-9]', '1234')\n",
    "# 패턴에 일치하는 데이터가 있으면 match 객체 리턴\n",
    "# 없으면 None 리턴\n",
    "print(match)\n",
    "match2=re.match('[0-9]', 'abc')\n",
    "print(match2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54ac5e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@안녕하세요 반갑습니다^^  의미없는 숫자는...!!!\n",
      " 안녕하세요 반갑습니다 의미없는 숫자는 \n"
     ]
    }
   ],
   "source": [
    "string='@안녕하세요 반갑습니다^^ 486 의미없는 숫자는...!!!'\n",
    "# 숫자 데이터 제거하기\n",
    "p=re.compile('[0-9]+')\n",
    "result=p.sub('',string)\n",
    "print(result)\n",
    "# 특수문자 제거하기\n",
    "p=re.compile('\\W+')\n",
    "result=p.sub(' ',result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79410bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['안녕하세요 반갑습니다', 'My job is Programmer', 'CC++ python']\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import sys\n",
    "text_data=['안녕하세요 반갑습니다.', 'My job is Programmer.', 'C&C++ ,python']\n",
    "# 구두점 딕셔너리를 생성\n",
    "punctuation=dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                         if unicodedata.category(chr(i)).startswith('P'))\n",
    "result=[string.translate(punctuation) for string in text_data]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0bf2216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\user\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06152fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f2f9401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'science', 'of', 'today', 'is', 'the', 'technology', 'of', 'tomorrow']\n",
      "['품질은 양보다 중요합니다 한 번의 홈런이 두번의 2루타보다 낫습니다.', '혁신은 현존하는 수천 가지 것들 중에 아니라고 말하는 것이다.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "string='The science of today is the technology of tomorrow'\n",
    "print(word_tokenize(string)) \n",
    "string=\"품질은 양보다 중요합니다 한 번의 홈런이 두번의 2루타보다 낫습니다. 혁신은 현존하는 수천 가지 것들 중에 아니라고 말하는 것이다.\"\n",
    "print(sent_tokenize(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e07c377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1월', '4월']\n"
     ]
    }
   ],
   "source": [
    "# 불용어 제거 - 한글은 불용어 사전이 없기에 직접 만들어야 한다.\n",
    "word_korean=['1월','2월','3월','4월']\n",
    "stopwords=['2월','3월']\n",
    "print([i for i in word_korean if i not in stopwords])\n",
    "# i for i in word_korean if i not in stopwords 는 작업을 수행해서\n",
    "# generator를 생성. 이는 이터레이터로 접근할 수 있는 객체임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9501c7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chief', 'president', 'kenedy', 'move']\n",
      "['chief', 'president', 'kenedy']\n"
     ]
    }
   ],
   "source": [
    "# 영문도 해보자.\n",
    "from nltk.corpus import stopwords\n",
    "word_english=['chief','the','an','and','president','kenedy', 'move']\n",
    "result=[w for w in word_english if not w in stopwords.words('english')]\n",
    "print(result)\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "result=[w for w in word_english if not w in ENGLISH_STOP_WORDS]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "944b9a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All', 'pythoners', 'have', 'pythoned', 'poorly', 'at', 'least', 'once']\n",
      "all\tpython\thave\tpython\tpoorli\tat\tleast\tonc\t\n",
      "al\tpython\thav\tpython\tpoor\tat\tleast\tont\t"
     ]
    }
   ],
   "source": [
    "# 영문 어간 추출\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "string=\"All pythoners have pythoned poorly at least once\"\n",
    "# 단어 토큰화\n",
    "words=word_tokenize(string)\n",
    "print(words)\n",
    "# 어간 추출\n",
    "ps_stemmer=PorterStemmer()\n",
    "for w in words:\n",
    "    print(ps_stemmer.stem(w), end='\\t')\n",
    "print()\n",
    "# 어간 추출\n",
    "ls_stemmer=LancasterStemmer()\n",
    "for w in words:\n",
    "    print(ls_stemmer.stem(w), end='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2044621c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('little', 'JJ'), ('yellow', 'JJ'), ('dog', 'NN'), ('barked', 'VBD'), ('at', 'IN'), ('th', 'JJ'), ('persian', 'JJ'), ('cat', 'NN')]\n",
      "\n",
      "['dog', 'cat']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# 형태소 분석 - 품사 태깅\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "tokens=word_tokenize('The little yellow dog barked at th persian cat')\n",
    "tags_en=pos_tag(tokens)\n",
    "# 단어와 품사의 튜플 리스트로 출력\n",
    "# 명사 NN, 고유명사 NNP, 부사 RB, 동사 VBD, 동명사 현재분사 VBG, 형용사 JJ\n",
    "print(tags_en)\n",
    "print()\n",
    "#명사랑 고유명사만 뽑을래\n",
    "print([word for word, tag in tags_en if tag in ['NN', 'NNP']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c1c3130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting konlpy\n",
      "  Using cached konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from konlpy) (4.9.1)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from konlpy) (1.23.5)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from konlpy) (1.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (22.0)\n",
      "Installing collected packages: konlpy\n",
      "Successfully installed konlpy-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "51748ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['태양계', '지금', '약', '46억년', '전', '거대', '자', '구름', '일부분', '중력', '붕괴', '형성']\n",
      "['태양계', '는', '지금', '으로부터', '약', '46억년', '전', '거대', '하', 'ㄴ', '불', 'ㄴ', '자', '구름', '의', '일부분', '이', '중력', '붕괴', '를', '일으키', '면서', '형성', '되', '었다', '.']\n",
      "[('태양계', 'N'), ('는', 'J'), ('지금', 'N'), ('으로부터', 'J'), ('약', 'N'), ('46억년', 'N'), ('전', 'N'), ('거대', 'N'), ('하', 'X'), ('ㄴ', 'E'), ('불', 'P'), ('ㄴ', 'E'), ('자', 'N'), ('구름', 'N'), ('의', 'J'), ('일부분', 'N'), ('이', 'J'), ('중력', 'N'), ('붕괴', 'N'), ('를', 'J'), ('일으키', 'P'), ('면서', 'E'), ('형성', 'N'), ('되', 'X'), ('었다', 'E'), ('.', 'S')]\n"
     ]
    }
   ],
   "source": [
    "# 한글 형태소 분석\n",
    "from konlpy.tag import Kkma\n",
    "text='태양계는 지금으로부터 약 46억년 전 거대한 분자 구름의 일부분이 중력 붕괴를 일으키면서 형성되었다.'\n",
    "# kkma=Kkma()\n",
    "# #문장 분석\n",
    "# print(kkma.sentences(text))\n",
    "# # 단어 분석\n",
    "# print(kkma.nouns(text))\n",
    "# # 형태소 분석\n",
    "# print(kkma.pos(text))\n",
    "# 다른 형태소 분석기\n",
    "from konlpy.tag import Hannanum\n",
    "hannanum=Hannanum()\n",
    "# 단어 분석\n",
    "print(hannanum.nouns(text))\n",
    "# 형태소 분석\n",
    "print(hannanum.morphs(text))\n",
    "print(hannanum.pos(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d347cf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beats' 'both' 'germany' 'good' 'hate' 'is' 'japan' 'love' 'my' 'puppy'\n",
      " 'sweden']\n",
      "[[0 0 0 0 0 0 0 1 1 1 0]\n",
      " [0 0 0 1 0 1 0 0 0 0 1]\n",
      " [0 0 0 0 1 0 1 0 0 0 0]\n",
      " [1 1 1 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# BoW(Bag of Word) - 단어의 개수\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "text_Data=np.array([\n",
    "    'I love my puppy',\n",
    "    'Sweden is good',\n",
    "    'I hate japan',\n",
    "    'Germany beats both'\n",
    "])\n",
    "count=CountVectorizer()\n",
    "bag_of_words=count.fit_transform(text_Data)\n",
    "# 이렇게 부르면 희소행렬\n",
    "# print(bag_of_words)\n",
    "# 밀집 행렬의 형태로 출력하려면\n",
    "print(count.get_feature_names_out())\n",
    "print(bag_of_words.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "df2b1995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'love': 5, 'my': 6, 'puppy': 7, 'sweden': 8, 'is': 4, 'good': 3, 'germany': 2, 'beats': 0, 'both': 1}\n",
      "[[0.         0.         0.         0.         0.         0.53177225\n",
      "  0.659118   0.53177225 0.        ]\n",
      " [0.         0.         0.         0.49552379 0.61418897 0.\n",
      "  0.         0.         0.61418897]\n",
      " [0.         0.         0.         0.         0.         0.70710678\n",
      "  0.         0.70710678 0.        ]\n",
      " [0.         0.         0.70710678 0.70710678 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.61418897 0.61418897 0.49552379 0.         0.         0.\n",
      "  0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "text_Data=np.array([\n",
    "    'I love my puppy',\n",
    "    'Sweden is good',\n",
    "    'l puppy love',\n",
    "    'Germany good',\n",
    "    'Germany beats both'\n",
    "])\n",
    "# tf-idf 객체 생성\n",
    "tfidf=TfidfVectorizer()\n",
    "feature_matrix=tfidf.fit_transform(text_Data)\n",
    "# print(feature_matrix)\n",
    "print(tfidf.vocabulary_)\n",
    "print(feature_matrix.toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
